{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IEEE FRAUD NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def import_data(file):\n",
    "    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n",
    "    df = pd.read_csv(file, parse_dates=True, keep_date_col=True, index_col='TransactionID')\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\tSuccessfully loaded train_identity!\n",
      "\tSuccessfully loaded train_transaction!\n",
      "\tSuccessfully loaded test_identity!\n",
      "\tSuccessfully loaded test_transaction!\n",
      "\tSuccessfully loaded sample_submission!\n",
      "Data was successfully loaded!\n",
      "\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('Loading data...')\n",
    "\n",
    "train_identity = import_data('train_identity.csv')\n",
    "print('\\tSuccessfully loaded train_identity!')\n",
    "\n",
    "train_transaction = import_data('train_transaction.csv')\n",
    "print('\\tSuccessfully loaded train_transaction!')\n",
    "\n",
    "test_identity = import_data('test_identity.csv')\n",
    "print('\\tSuccessfully loaded test_identity!')\n",
    "\n",
    "test_transaction = import_data('test_transaction.csv')\n",
    "print('\\tSuccessfully loaded test_transaction!')\n",
    "\n",
    "\n",
    "test_identity.columns = train_identity.columns\n",
    "\n",
    "print('Data was successfully loaded!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging data...\n",
      "Data was successfully merged!\n",
      "\n",
      "Train dataset has 590540 rows and 433 columns.\n",
      "Test dataset has 506691 rows and 432 columns.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Merging data...')\n",
    "train = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\n",
    "test = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n",
    "\n",
    "# \"isFraud\" bagımlı degiskenini y_train degiskenine atadık\n",
    "y_train = train[\"isFraud\"]\n",
    "# Train bagimsiz degiskenleri\n",
    "df_train = train.drop(\"isFraud\", axis=1)\n",
    "\n",
    "print('Data was successfully merged!\\n')\n",
    "\n",
    "del train_identity, train_transaction, test_identity, test_transaction\n",
    "\n",
    "print(f'Train dataset has {train.shape[0]} rows and {train.shape[1]} columns.')\n",
    "print(f'Test dataset has {test.shape[0]} rows and {test.shape[1]} columns.')\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOT: LÜTFEN YUKARIDAKİ HİÇBİR DEĞERİ VE DEĞİŞKENİ DEĞİŞTİRMEYİN.\n",
    "\n",
    "Örneğin train dosyasında değişiklik yapacaksanız aşağıdaki gibi copyasını alarak yapınız.\n",
    "df_train_copya = df_train.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Ozan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Ümit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Muhammet(Alm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Ismail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-) (card1 - card4 - addr1) ile (TransactionAmt - id_02 - D15) arasinda uretilen degiskenler\n",
    "\n",
    "- https://www.kaggle.com/davidcairuz/feature-engineering-lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_a = ['TransactionAmt', 'id_02', 'D15']\n",
    "columns_b = ['card1', 'card4', 'addr1']\n",
    "\n",
    "for col_a in columns_a:\n",
    "    for col_b in columns_b:\n",
    "        for df in [train, test]:\n",
    "            df[f'{col_a}_to_mean_{col_b}'] = df[col_a] / df.groupby([col_b])[col_a].transform('mean')\n",
    "            df[f'{col_a}_to_std_{col_b}'] = df[col_a] / df.groupby([col_b])[col_a].transform('std')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### card1 - TransactionAmt\n",
    "\n",
    "- card1 degiskeni onemli bir degisken, kullanici belirlemede ise yarayabilecek bir degisken, burada yapilan her bir harcamanin (transactionID) card1 bilgisi var ama bu card ile baska harcamalarda yapilmis, bu card ile yapilan toplam harcamalarin ortalamasini (std icin de yapiyor) belirliyor ve sadece bu harcamadaki miktar ile oranina bakiyor,\n",
    "\n",
    "- mesela x card, 3 farkli islemde kullanilmis ve her islemde 5, 10, 15 para birimlik harcama yapilmis, sonucta x card islem basina harcama ortalamasi 10\n",
    "\n",
    "- 1.islemde gercek harcama 5/ ortalama harcama 10\n",
    "- 2.islemde 10/10\n",
    "- 3.islemde 15/10 \n",
    "\n",
    "- bu sekilde her islemdeki card'in o islemdeki harcamasinin toplam card harcama ortalamasina oranini tespit ediyoruz\n",
    "\n",
    "- bu islem hem MEAN hem de STD icin ayri ayri yapiliyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionID\n",
       "2987000    0.194640\n",
       "2987001    0.123777\n",
       "2987002    0.608150\n",
       "2987003    0.405133\n",
       "2987004    0.515612\n",
       "Name: TransactionAmt, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train['TransactionAmt'] / train.groupby('card1')['TransactionAmt'].transform('mean')).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### card4 - TransactionAmt\n",
    "\n",
    "- card4 kartin visa, mastercard, debit vs... olup olmadigini bilgisini tutuyor, burada da ayni yukarida oldugu gibi, her bir islemdeki tutarin genel ortalamaya oranini veriyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionID\n",
       "2987000    0.257761\n",
       "2987001    0.219054\n",
       "2987002    0.443070\n",
       "2987003    0.377679\n",
       "2987004    0.377679\n",
       "Name: TransactionAmt, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train['TransactionAmt'] / train.groupby('card4')['TransactionAmt'].transform('mean')).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### addr1 - TransactionAmt\n",
    "- addr1 degiskeni zipcode bilgisi veriyor, yani ayni zipcode'dan yapilan islemlerin tamamindaki miktarin ortalamasi ile ayni zipcode'dan yapilan her bir islemin orani hesaplanmis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionID\n",
       "2987000    0.509556\n",
       "2987001    0.186032\n",
       "2987002    0.445765\n",
       "2987003    0.368830\n",
       "2987004    0.306863\n",
       "Name: TransactionAmt, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train['TransactionAmt'] / train.groupby('addr1')['TransactionAmt'].transform('mean')).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### card1 - id_02\n",
    "\n",
    "- card1'i grupluyor ve id_02 degerlerinin mean ve std'sini cikartiyor, \n",
    "- id_02 degeri 1'den baslayip yaklasik 1 milyona kadar artan, ortalamasi 175000 civari olan bir sayisal deger, ne ifade ettigini anlayamadim\n",
    "- id_02'yi anlayamadigim icin buradaki feature uretmenin de mantigini cozemedim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train['id_02'] / train.groupby('card1')['id_02'].transform('mean')).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### card4 - id_02  - addr1 - id_02\n",
    "- benzer sekilde id_02 degiskeni ile card4 ve addr1 arasindaki iliskiyi de anlayamadim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (card1 - D15), (card4 - D15), (addr1 - D15)\n",
    "- D15 degiskeni hakkinda bir kanaat olusmadigindan bu yeni feature olusturmanin mantigi da kavranamadi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-) TransactionAmt'nin LOGORITMASI\n",
    "- gerek var mi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['TransactionAmt_Log'] = np.log(train['TransactionAmt'])\n",
    "test['TransactionAmt_Log'] = np.log(test['TransactionAmt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Berkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Muhammet (Nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIGHT GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST  MODELI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
